
**Dec.2025**
---
### 그래프 컬럼 설명
**ta_ymd :** 기준 년월일(YYYYMMDD) / **cty_rgn_no :** 시·군·구 코드

**admi_cty_no :** 행정동 코드(행정안전부 기준) / c**ard_tpbuz_cd :** 카드사 업종 분류 코드

**card_tpbuz_nm_1 :** 업종 대분류명 / **card_tpbuz_nm_2 : **업종 중분류명

**sex :** 성별(M/F) / **age :** 연령대 코드(01: 0–9세, 02: 10–19세, …, 11: 100세 이상)

**hour :** 시간대 코드(01: 00–06시, 02: 07–08시, 03: 09–10시, …, 10: 23시)

**day :** 요일 코드(01: 월, 02: 화, 03: 수, 04: 목, 05: 금, 06: 토, 07: 일)

**amt :** 매출 금액 / **cnt : 매출 건수**

""" 양식
# 📅 개발 및 학습 일지 (Development Log)
## 15.Dec.2025 [DAY-8]
## ✅ 한 일
## 배운점(TIL)
### TIL (간단한 Keyword 정리)
## 트러블슈팅 (Troubleshooting)

### 1. 파일중복
 - **문제 :** 
 - **원인 :** 
 - **방법 :** 
 - **결과 :** 


## 추가 공부




"""
# 📅 개발 및 학습 일지 (Development Log)
## 15.Dec.2025 [DAY-8]
## ✅ 한 일
 - [x] pd.cut으로 월초/중반/월말 분리
 - [x] 대용량 파일처리 (Parquet)
 - [X] 더위가설 수립 및 증명

## 배운점(TIL)
 - 가설 증명
 - '더위'가 사람들의 소비성향을 위축시켰다.
 - 고려해야 할 요소 (월급날)
 - 월 자본흐름 확인
     - pd.cut을 통해 구간 분리(월 초, 중반, 월 말) 7월 한달 자본 흐름 확인
     - ![July](../02_src/04_Food_Analysis/01_images/July_Month_cut.png) 
          - 월급날과 가까운 중순일수록 소비가 주춤해지는 현상 발견
     - 6월 8월 검증
     - ![June](../02_src/04_Food_Analysis/01_images/June_Month_cut.png)
     - ![Aug](../02_src/04_Food_Analysis/01_images/Aug_Month_cut.png)
     - 세 구간 전부 중순에는 자본의 흐름이 약해지는 것을 관찰할 수 있음.

 - 이천시 막대그래프(더위떄문인지 확인)
     - ![WEEK07](../02_src/04_Food_Analysis/01_images/week07_cnt.png)
     - 7월은 6월, 8월에 비교했을 때, '화,수,목'이 높다고 했었음.
     - 하지만, 7월이 이상한 흐름인지 확정적인 결론을 내릴 수 없었고, 패턴을 찾지 못하였기에 1월~10월까지 현재 올라와있는 자료들을 전부 다운로드함(대용량 파일 처리 필요)

 - 대용량 파일 처리
     - 첫번째 난관
         - 10개의 대용량 파일을 어떻게 효율적으로 메모리낭비없이 사용할것인가?
         - DRY(Don't Repeat Yourself) 원칙에 따라서 직접 반복하는것은 무의미함.
         - 즉, 결국 '모듈화'를 선택했음.
    
     - 모듈화
         - SQL, R언어를 사용할 떄 '패턴 매칭'을 기억하고 파일 형식이 비슷한 점을 사용함.
         - 'data_loader.py' 파일을 제작하고, 패턴매칭을 위한 ```glob``` 모듈 사용
         - 또, 'sys', 'os' 사용법에 대해 숙지함.(\__file_\_ / os.path.join / dirname / abspath)
         - 메모리 사용량을 줄이기 위해 date, category 타입 변경 포함(결합도와 응집도때문에 고민했으나 나중에 수정할 때를 참고해 매핑자료를 따로 첨부함)
         - ```classify_period``` 라는 함수를 'data_loader.py' 안에 넣어놨는데, 언더바('_') 하나로 시작하는 것은 암묵적으로 '내부용' 이라는 것을 학습

     - 두번째 난관(Parquet)
         - Parquet 이란 무엇인가?
         - 이걸 왜 사용하는가 ?
    
    - Parquet(파케이)
         - '.csv' 파일은 사람이 읽을 수 있지만 컴퓨터에게는 "파싱(Parsing)"비용이 비싼 포맷
         - 파싱(Parsing) : 컴퓨터가 알아들을 수 있게 쪼개서 번역하는 작업
         - '.csv' vs 'Parquet'
             - 컴퓨터는 사람의 언어를 이해하지 못하므로 그를 번역하기 위해 CPU와 시간을 많이 사용함 ( 비싸다고 한 이유)
             - Parquet(파케이)는 컴퓨터가 이해할 수 있는 '모국어'같은 존재임.
         **1월~10월 데이터병합 7.8초**
         **Parquet를 통한 호출 0.7초**
    
    - 사전 집계(Pre-Aggregation)
         - Parquet를 통해 이해하기 쉽고 빠른 형태로 변환했어도 500만개 행을 다 읽는건 비효율적임
         - 따라서, 원하는 컬럼을 뽑아서 사용하는 것이 훨씬 좋음.
     **즉, Parquet는 나만의 데이터베이스**라는 비유를 들 수 있음.

 - 대용량 파일 시각화
     - Lineplot을 이용해 전체적인 흐름을 보고자 함.
     - 색깔은 hue='period'를 통해 해결했으나, '월~일' 까지의 표시를 해야했음.
     - 그냥 xticks()를 통해 조절한다면 이름표만 달은 것과 다름없음
     - 정렬기준을 만들고 적용시키고자 함.
         - 하지만, 원하는 대로 정렬이 되지않았음.
         - pd.Categorical(적용할 컬럼, Categories=정렬기준, ordered=True) -> 카테고리에도 정렬 부여

 - 그래프
     - ![1월-10월_매출총액_평균](../02_src/04_Food_Analysis/01_images/Jan_Oct_amt_mean.png)
     - ![1월-10월_매출건수_평균](../02_src/04_Food_Analysis/01_images/Jan_Oct_amt_mean.png)
         - ※주의해야할 점
             - 데이터는 11월 12월이 빠져있어 가을과 겨울 집계가 정확하지 않음. (겨울: 1,2,12 / 가을: 9,10,11 / 봄: 3,4,5월 / 여름: 6,7,8월 )
             - 따라서, 합계보다는 평균을 바라봐야 함.
         - 가을 : 월~일 전 요일에 걸쳐 가장 높으며, 특히 주말(토요일)에 압도적인 피크를 찍음. ->
         - 2위 여름 (주황색 실선):주문 건수는 가을 다음으로 많지만, **매출총액 평균(객단가)**은 가을보다 낮음.
             -손님은 많지만, 가을에 비해 상대적으로 저렴한 메뉴를 소비하거나 소액 결제가 많다는 뜻.
         - 3위 봄(파랑) & 겨울(빨강): 전반적으로 비슷한 하위권을 형성함.
     
     - 가설 및 해석
         - 소비 횟수 측면에서 여름(주황색) 그래프는 바닥을 치지 않았음. 오히려 봄(파랑)이나 겨울(빨강)보다 주문 건수가 더 많음.
         - 더위 때문에 소비가 위축되었다면 여름 선이 봄보다 아래에 있어야 하는데, 실제로는 여름에 돈을 더 썼거나 비슷하게 사용함.
         - 즉, 더위가 사람들의 발길을 끊게 만들지 않았음. (가설 기각)
    
     - 새로운 인사이트:
         - 가을 역시 전부 집계가 되지 않았더라도, 매출건수와 매출총액 평균이 매우 높은 '돈이 되는' 성수기 계절임.(특수하게 소비가 폭발하는 시기 -> 왜인지 분석예정)
         - 이천시의 7월 데이터만을 보고 '평일 마케팅' 고려했으나, 오히려 '금,토,일'에 집중해야함.
             - 하지만, 계절상 '여름'이 평일에 강하고 매출건수와 매출총액이 높기 때문에 여름에는 '가벼운 프로모션' 진행을 할 수 있다.
         - '겨울'은 집계가 덜 되었다는 점을 감안하더라도, 월~일 내내 가장 바닥에 있었음.
             - 즉, 사람이 안오는 것과 동시에 적게 쓴다는 것
             - 객단가를 강제로 높이는 세트 메뉴(Upselling) 구성을 고려할 수 있음.
         - '일요일'에 손님은 금요일보다 더 많이 오는데, 돈은 덜 사용함.
             - '목/금'요일은 회식과 술자리 위주로 테이블 단가가 높지만, '일요일'은 다음 날 출근을 고려해 술을 덜 마시고 가벼운 식사를 함.
             - 회전율을 높이는 전략 고려 가능.

### TIL (간단한 Keyword 정리)
 - 데이터 용량 처리(Parquet, data_loader.py)
 - 가설 기각 및 인사이트 도출
 - pd.Categorial(), pd.cut() 학
## 트러블슈팅 (Troubleshooting)

### 1. 대용량 파일처리
 - **문제 :** 많은 양의 '.csv'파일을 처리하는 방법 고려
 - **원인 :** 메모리, 시간, 용량, 효율 낭비를 예방해야 함.
 - **방법 :** glob 모듈을 통한 패턴 매칭과 Parquet
 - **결과 :** Parquet를 통한 호출 0.7초 (가장 빠른 시간)

### 2. 지식의 깊이(실무경험)
 - **문제 :** 대용량 파일 처리 전체
 - **원인 :** 처음으로 마주하는 빅데이터와 모르는 단어들이 많았습니다.
 - **방법 :** AI에게 물어본 후 문법 공부 및 일일이 타이핑
 - **결과 :** Parquet, glob모듈, 대용량 파일처리 

## 추가 공부
 - **파싱(Parsing):** 비정형 문자열(Raw Data)을 문법 규칙에 따라 의미 있는 구조(Structured Data)로 변환하는 과정.
 - **pd.Categorical:** 요일(월~일)과 같이 순서가 있는 데이터(Ordinal Data)를 정렬할 때 사용하는 판다스 기능.



# 📅 개발 및 학습 일지 (Development Log)
## 12.Dec.2025 [DAY-5]
## ※DEV_LOG 파일 및 파일정돈 (구조화 적용일) [TIL 참고]
## ✅ 한 일
 - [X] Monorepo(모노레포)도입
 - [X] Rename Refactoring (리네임 리팩토링)
 - [X] 사용자 코드 조각(User Snippets) 

## 배운점(TIL)
 - 비효율성
     - 'config.py', '.csv', 'my_plotting.py' 등을 매 프로젝트마다 파일 입력은 비효율적이라고 느낌
     - 결과물이 아닌 프로젝트가 여러개 생성되는 것 역시 무의미
     - 불러오기를 사용하기 위해선 파일 구조를 개선해야 한다고 느낌
     - 새 프로젝트 마다 'origin', 'git init', 'git remote add' 등 반복적인 git 명령어 사용과 발생하는 오류
     - 사용자의 실수로 이전 프로젝트에 덮어씌울 가능성 존재
     
 - Multirepo -> Monorepo
     - Monorepo 선택이유는 다음과 같음.
         - 지속적으로 업데이트 되어야 하고, 파일을 한 곳에 저장한 후 불러오기를 사용해야함 -> 불필요한 용량 낭비 방지
         - ```README.md``` 파일을 한눈에 보고 싶음 -> ```DEV_LOG.md``` 로 통합하고 대체함.
         - 파일 작업 현황을 한 눈에 볼 수 있어야 함 (유저와 본인)
         - 파일 수정과 작업에 용이해야함.
         - 다음 프로젝트 진행 시 ' 더 알찬 프로젝트 ' 들로 Git을 채울 수 있음 등

 - Monorepo & Rename Refactoring 
     - ![File_Structure](../02_src/04_Food_Analysis/01_images/File_Structure.png)


     - ```00_Common_Data``` -> 작업 데이터 파일 '.csv'
     - ```01_Shared_Lib``` -> 자주 사용하는 모듈과 이름 변경
         - 'config.py', 'my_plotting.py' -> [['constants.py','barh_plot.py']] (매핑자료, barh 시각화 함수)
     - ![Project_name](../02_src/04_Food_Analysis/01_images/src_name.png)
     - ```02_src``` -> 프로젝트 작업들 (데이터 분석연습 및 프로젝트)
     - ```03_Docs``` -> 문서 작업으로써 ```DEV_LOG.md``` 파일 위치
     - ```99_Archive``` -> 저장소 및 폴더 정돈을 위한 폴더 (난잡 방지)

 - User Snippets
     - import와 메모리 사용량을 위한 타입변경은 여전히 매 프로젝트마다 해야하는 번거로움
     - Snippets 사용
         - 'init_ds' 사용 시 모듈 호출과 타입변경코드 나옴
             - 1. 모듈 호출 적용
             - 2. 'ctrl + /' -> 주석 제거 후 타입변경 코드 적용


### TIL (간단한 Keyword 정리)
- Monorepo
- Rename Refactoring
- User Snippets
- File Structuring

## 트러블슈팅 (Troubleshooting)

### 1. 파일중복
 - **문제 :** '.csv'파일을 새 프로젝트가 시작할 때마다 복사해서 넣어야 함 (용량낭비)
 - **원인 :** 진행하는 프로젝트 수 만큼 파일을 붙여넣기 때문(이를, Multirepo 방식이라고 함)
 - **방법 :** Git이라는 최상위 폴더에 통합, 파일 정리 + Rename Refactoring 
 - **결과 :** 용량을 효율적으로 사용하고, 번거로운 작업을 반복하지 않게 됨.

### 2. Snippets
 - **문제 :** 새 프로젝트마다 import와 카테고리 타입 변경이 비효율적임.
 - **원인 :** 필요한 내용(필요 코드)을 미리 저장하지 않았기 때문임. 
 - **방법 :** VSCode의 User Snippets 기능으로 초기 설정 코드를 자동화
 - **결과 :** `init_ds` 키워드 입력 시 필수 라이브러리와 전처리 코드가 자동 완성되도록 설정함.
    - 환경 설정 시간이 **1분에서 3초로 단축**됨.
    - 모든 프로젝트에서 **동일한 표준 설정**을 강제하여 일관성 유지.

## 추가 공부
 - User Snippets (사용자 코드 조각)
     - 단축키(키워드)로 불러오는 초기 설정임.
     - 오타를 방지하고 속도, 표준화를 위해 많이 사용하는 VSCode 내장기능. IDE(통합 개발 환경)에 대부분 내장되어 있음.

# 📅 개발 및 학습 일지 (Development Log)
## 11.Dec.2025 [DAY-4]
## ✅ 한 일
- Matplotlib 객체 지향 방식(`ax`)과 이중축(`.twinx()`)을 활용한 심층 시각화(`진행 방향 결정`) 구현
- 요일별/일별 매출 패턴 분석 및 타 월(Month) 데이터와의 시계열 일관성 확인
- 디렉토리 구조 리팩토링 (`src`, `data`, `images` 분리)

## 배운점(TIL)
 - **이중축(Duelaxis)**그래프 도전
 - **객체생성** ax2, ax1
     - ax1 도화지에는 barplot, ax2 도화지는 ax2 = ax1.twinx() 적용
         - '.twinx()'는 서로 단위가 다른 두 데이터를 하나의 그래프에 겹쳐 보고 싶을 때 사용
         - 즉, ax1 도화지에 ax2를 같이 사용함.

 - 일 컬럼
 - 기존 df['ta_ymd'] 컬럼을 사용하기에는 너무 길다는 문제점이 있음
     - 전부 7월의 데이터이므로 title에 2025년 07월이라고 명시
     - pd.to_datetime(df['ta_ymd'], format="%Y%m%d) 함수로 데이터 포맷
     - df['ta_ymd'].dt.day -1 적용(index 맞추기 위함)

 - 막대그래프
     - 막대그래프는 '#4c72b0' 색으로 매출총액을 나타냄
     - plt.axvline()을 사용하여 일주일이 지나면 검정색 선(linestyle='-.')으로 표시
     - '매출총액' 글자가 겹치자 rotation=0(수평), labelpad()=10 으로 조정하여 해결함.

 - 라인그래프
     - 라인그래프는 'orange' 색으로 매출건수를 나타냄
     - ax2.tick_params(axis='y', labelcolor='orange') 적용 -> y축 사용 / y축 레이블 색은 주황색
     - '매출건수' 글자를 rotation=0 (수평)으로 조절함

 - 그래프 조정
 - 발표용 강조 자료
     - 기존 막대그래프들에게 '#6f9dbd' 색깔 적용 ( 기존보다 연함 )
     - bar와 line의 투명도를 'alpha=0.7'로 설정함
     - 특정강조 그래프에는 'red' 색깔 적용
     - axvline()은 4구간이 있었으나 if문을 적용하여 하나만 범례에 띄웠음.
     - [막대그래프 도화지] ax1.set_xticklabels(range(1,32)) 가로축 조정

    **전체 흐름 시각화로 인해 상세분석할 날(일)과 프로젝트 분석 방향을 정할 수 있었음**

 - 결과 및 해석
         - ![Duel_sat](../02_src/03_Month_Analysis/01_images/Duelaxis_Saturday.png)
         - 1. 토요일은 매출건수도 높고, 매출금액도 높다
         - 2. 일요일은 매출건수는 적으나, 그에 비해서는 매출금액이 높다. 하지만, 일주일 중에서는 매출금액이 가장 적은 날이다.
            - ![Duel_Tue-Thur](../02_src/03_Month_Analysis/01_images/Duelaxis_Tue-Thur.png)
         - 3. 화,수,목은 큰 변화없이 꾸준한 크기와 비교의 모습을 보임
         - 4. 쉬는 날이 가까워질수록(다음날이 쉬는 날 일수록) 매출건수와 매출금액은 증가하는 편이다.

    - 가설
    - 14일 - 20일까지는 **'더위'가 사람들의 소비성향을 감소시켰다.**( '특이일', '이벤트'같은 날들이 매출에 영향이 있다는 가설아래 )
         - 근거
         - ![Sat-Sun](../02_src/03_Month_Analysis/01_images/Duelaxis_Chobok.png)
         - 1. 다른 주 금,토요일에 비해 18일, 19일은 매출총액과 매출건수가 확연히 줄어들었다.
         - ![If_Chobok](../02_src/03_Month_Analysis/01_images/Duelaxis_Chobok_02.png)
         - 2. 다른 주 화,수,목요일에 비해 15,16,17일은 감소하는 모습을 보인다.
      - 3. 2025년 7월은 '삼복 중 초복'으로 매출이 상승하는 캘린더 효과(Calender Effect)가 있었어야 할 것이다.

         - **생각해야 할 가능성**
             - 절대적인 '매출총액'의 값이 낮은 것은 사실이나, 다른 주 '금', '토' 매출 건수에 비해서 '매출총액'은 높은 편
                 - '18일' 금요일은 대체로 건수는 적으나 총액은 비슷함.

             - '월급날'의 영향
                 - 사람들의 지갑은 '월급날'에 가까울 수록 가벼워 질 것임
                 - 심화분석 :  월 초/ 중순 / 월 말 그룹화를 통해 매출총액 비교


     - 일요일의 '객단가'는 가장 높을 것이다.
         - 근거
         - 1. '토요일'은 건수와 매출총액이 같이 상승하는 모습
         - 2. '일요일'은 건수는 낮은 것에 비해서 매출총액이 높은 모습

 - **요일별 매출총액/매출건수 비교**
 
 - 요일 별 막대그래프
     - 막대그래프는 '#ff9873' 색으로 색칠, 강조 색깔은 'red'임
     - df['day'] 컬럼이 'category' 였기 때문에 또 다시 ㄱ,ㄴ,ㄷ 순으로 정렬
     - 값이 월,화,수, ... 일 순으로 정렬되어 있지 않아 값으로도 정렬 불가능

 - 요일 정렬
     - my_order[월-일] 생성 후 order=my_order 도입
     - plt.text에서도 정렬이 되어있지 않아 .reindex(my_order)로 정리
 
 - 그래프 조정
     - 몰입도를 위해 ax.patch.face_color / ax.face_color를 사용해 '#f0f0f0ed'로 색깔 조정
     - axhline()으로 표시하여 발표자료로써 이해하기 쉽게 만듬

 - 결과 및 해석
     - ![weekday7](../02_src/03_Month_Analysis/01_images/weekday_bar.png)
         - 대부분 화,수,목 은 꾸준한 지표를 차지(15.7%/15.5%/15.5%)했으며 금,토에 매출건수와 매출총액이 많이 증가함.
         - 즉, 이천시의 2025년 7월은 평일에 마케팅을 고려할 수 있음

     - 검증 (다른 월도 그러한지 6월, 8월 데이터를 가져와 시각화)
     - ![weekday6](../02_src/03_Month_Analysis/01_images/week06_bar.png)
     - ![weekday8](../02_src/03_Month_Analysis/01_images/week08_bar.png)
         - Colab 환경에서 제작했던 '수원시'의 요일별 그래프 역시 그러함. 
         - 6월, 8월 그래프는 화,수,목요일이 '토요일'을 넘긴적이 없었음.
    
     - 가설
     - 반드시 202507월에는 평소의 '금', '토'일을 이기는 무언가가 있었을 것이다.
         - 특히, 16일과 17일에 '초복'으로 인한 사람이 몰렸을 수 있다.

 - 파일정리
 - 현재 구조의 비효율성
     - 파일들을 넣을 정확한 명칭을 찾음
     - 'images' 폴더를 만들어 사진들을 정리
     - 'data' 폴더를 만들어 '.csv'파일 정리
     - 'src' 폴더를 만들어 '.py' 모듈 정리


### TIL (간단한 Keyword 정리)
 - 객체지향방법 + .twinx()로 이중축(Duelaxis)그래프 생성
 - 심화분석할 날(일) 탐색 및 프로젝트 진행방향 결정
 - 요일별 막대그래프 생성
 - reindex(), my_order 생성으로 커스터마이징 정렬
 - 같은년도 다른 월 데이터로 요일별 그래프의 이상 검증(탐지)
 - axvline, axhline 으로 구분 및 기준 생성 ( 범례는 하나 )
 - 데이터포맷 및 투명도 조정, 강조색상 사용으로 그래프 강조
 - 'images', 'data', 'src' 등 폴더를 만들어 정리

## 트러블슈팅 (Troubleshooting)

### 1. 정렬방법
- **문제 :** df['day']는 'category'타입에 값이 들쭉날쭉해 값으로도 정렬 불가
- **방법 :** my_order로 원하는 정렬기준 생성
- **결과 :** 원하는 방식으로 정렬 + plt.text에 '.reindex(my_order)' 사용으로 텍스트 정렬

### 2. 값
- **문제 :** df.items()를 사용하지 않으면 개인적으로 값을 꺼내기 힘들어 했음
- **방법 :** iloc / loc 사용법 숙지
- **결과 :** 원하는 값 꺼내기 용이해짐.

### 3. 인덱스
- **문제 :** bar와 line 그래프의 인덱스가 일치하지 않는 문제(범주형, 수치형이기 때문)
- **방법 :** df['ta_ymd'].dt.day -1 적용
- **결과 :** 분석 데이터 왜곡현상 해결

## 추가 공부
 - [x] ax.set_ticks -> 눈금(Tick)이 찍힐 **'수학적 좌표(위치)'**를 정함
 - [x] ax.set_ticklabels-> 위에서 정한 위치에 적힐 **'글자(이름표)'**를 정함
 - [x] ax.set_label -> Y축 전체를 대표하는 **'제목'**을 달아줌.
 - [x] ax.tick_params -> 눈금(Tick)과 눈금 라벨(Label)의 스타일을 **미세 조정**함.

# 📅 개발 및 학습 일지 (Development Log)
## 10.Dec.2025 [DAY-3]
## ✅ 한 일
 - [x] 매핑자료 'config.py', 그래프 시각화 함수 'my_plotting.py' 모듈화
 - [x] bar(barh) 학습
 - [x] 그래프 디테일 학습


## 배운점(TIL)
 - 그래프 생성
 - 새로운 프로젝트 파일을 생성하면 다시 매핑자료 입력과 한글설치를 하는 일련의 과정들이 너무 귀찮게 느껴짐
     - 따라서, 'config.py'를 생성해 모듈화 함.(매핑자료와 한글설치 함수생성)
     - import 라이브러리 역시 모듈화 하려했음 -> '네임스페이스 오염'과 '명시적인 중요성'으로 인해 사용 비추천 -> 오류찾기도 어려움
     - ![Font_Module](../02_src/02_Cohort_Practice/images/Font.png)
    **간단하게 시간을 절약하고 작업의 효율성을 증가시킬 수 있었음**
 
 - 분석하는 연령대를 나누어 'card_tpbuz_nm_1'분석 (세그멘테이션) 
     - 일반적인 상향식 막대그래프는 가독성도 떨어지고 보기 불편하다고 느꼈음
         - label의 갯수가 많아 가독성이 떨어지고, 금액확인이 어려웠음
     - barh(수평막대그래프) 처럼 눕히는 방법 선택 (sns.barplot은 x와 y값만 바꾸면 됨)
     - 큰 값에서 작은 값으로 정렬하고 싶으나 'category' 타입은 ㄱ,ㄴ,ㄷ 순으로 정렬
         - 첫 번째, 데이터전처리 :  ```groupby```를 할 때 .sort_values(ascending=False)
         - order = data.index 파라미터를 추가 -> '데이터 순서 = 막대 순서 = 색상 리스트'로 1:1 매칭

 - 생성한 barh 그래프가 밋밋
     - sns.color_palette('Blues_r', len(x)) 으로 그라데이션 색깔을 x개만큼 생성 (큰 값이 가장 진함)
     - 참고로 palette('색깔_r')에서 _r 은 reverse의 약자임. -> 큰 값을 가장 진하게 하고 싶을 때 사용
     - 그래프의 외곽선이 답답하고 불편함
         - plt.gca().spines['position'].set_visible(False)을 통해 제거하고 왼쪽 축만 남김

 - **저번 *추가학습* 때 배운 객체지향적 방법적용**
     - fig, ax = plt.subplots(figsize=(x,y))를 통해 ax (그래프를 그릴 도화지) 생성
         - 앞으로 ax의 세부 설정이 가능해짐
         - 그래프의 x축을 지우기 위해 plt.xticks([]) 사용
             - 하지만 plt.grid(axis='x')를 표현할 수 없었음.
             - ax.tick_params()를 사용하고, ax.grid(axis='x') 사용으로 x축 수직선 적용 및 해결
             - 한 눈에 약 n배 인 것을 파악 가능하게 됨
    **그래프에서 객체지향적 접근과 상세한 튜닝으로 가독성, 심미성, 전문성을 챙길 수 있게 됨**
 
 - 데이터 레이블링
     - plt.text(x, y, s, weight, ha, va) 학습
     - 반복문(for)과 `enumerate`를 활용하여 모든 막대 위치에 정확한 수치 텍스트(`ax.text`)를 자동 배치.
         - Before : 퍼센트(pct)와 금액 값을 리스트를 따로 제작하고 text에 기입 ( 2번의 반복 )
         - Think : 반복문이 2갈래로 갈린 것은 i번째 라는 순서때문임
         - After : 논리 구조 개선과 enumerate(df.items())를 통해 반복문 한번으로 기입.

 - 그래프 변수
 - 생성한 그래프에 집단마다 변수와 내용물을 바꿔줘야 함 -> VScode의 ```F2``` 단축키 역시 불편함
     - 생성한 그래프를 함수로 변환(data, "그래프 제목", ax, 색깔(기본은 Blues_r))
     - barh 그래프는 레이블이 많은 경우 자주 사용할 것 같아 'my_plotting.py' 모듈화

 - 'my_plotting.py' 수정사항이 있을 때마다 VSCode를 껏다 켜야 하는 불편함
     - importlib.reload(mp)를 통해 적용

    **유지보수가 용이해졌고 수정도 간단함**
    
### TIL (간단한 Keyword 정리)
- 'config.py', 'my_plotting.py' 모듈화
- seaborn 기준 bar(x, y, palette, ax, order) / plt.text(x, y, s, weight, ha, va) 학습
- plt.gca().spines['postion'].set_visible(), ax 객체지향적 방법 도입 -> 그래프 전문성, 심미성, 가독성 확보

## 트러블슈팅 (Troubleshooting)

### 1. 아쉬운 시각화
- **문제 :** plt.xticks([]) 사용 -> plt.grid() x수직선 사용불가
- **원인 :** plt.grid()의 선은 눈금(Tick)의 위치를 기준으로 그리기 때문임
- **방법 :** ax를 통한 객체지향적접근과 세부설정(ax.set_ylabel, ax.grid(axis='x', alpha=0.5))
- **결과 :** 그래프에 대한 전문적인 접근과 가독성, 심미성 향상 가능.

### 2. 비효율적인 코드
- **문제 :** plt.text를 사용하기 위한 비효율(2번의 반복문)
- **방법 :** 논리구조 개선, enumerate 함수 사용
- **결과 :** 비효율(2번의 반복) 개선
     - *[DAY-4]Month_Analysis 요일 별 막대그래프*
         - Before : '걸린 시간: 0.0458 초'
         - After : '걸린 시간: 0.0481 초'

### 3. 수정 적용
- **문제 :** 'my_plotting.py' 파일 수정마다 VSCode를 껏다켜야하는 불편함
- **방법 :** importlib.reload(mp)로 해결
- **결과 :** VSCode를 끄지 않아도 적용 가능

## 추가 공부
 - __pycache__ : 파이썬 인터프리터가 소스 코드(.py)를 컴파일하여 만든 **바이트코드(Bytecode, .pyc)** 저장소
  -> 다음에 프로그램을 실행할 때, 컴파일 과정을 건너뛰어 **로딩 속도(Start-up time)**를 높일 수 있음
   -> 소스 코드만 있으면 언제든 자동 생성 -> Git에 올릴 필요 없는 파일

# 📅 개발 및 학습 일지 (Development Log)
## 09.Dec.2025 [DAY-2]
## ✅ 한 일
 - [x] Git과 VSCode 연결
 - [x] 기본적인 EDA(탐색적 데이터 분석)
 - [x] 함수와 파라미터 학습


## 배운점(TIL)
 - HEATMAP
 - 나이에 따른 시간대 별 매출총액을 보고 싶었음
     - 하지만, 일일이 Line그래프로 보기에는 양도많고 불편하고 가독성이 떨어짐
     - Heatmap이라는 함수 채택
     - Parameter(파라미터) 학습

 - Heatmap에 ```groupby```된 결과를 바로 넣으려다가 오류 발생
     - Heatmap은 2차원 행렬 구조가 필요함 -> pivot_table 학습

 - Heatmap의 숫자가 너무 커서 ( + 지수 표기법 표현) 읽기 어려웠음
     - 단위를 천만으로 맞추고 단위를 표시함.
     - fmt 파라미터를 사용하여 숫자를 정리

 - Heatmap 숫자가 밋밋하다는 생각이 듦.
     - '*_kws'를 사용해 숫자크기, bold체 등 세밀하게 제어
     - 컬러바(범례) 유무 및 레이블 설정

 **연령에 따른 시간대 별 소비성향을 색깔을 통해 한눈에 파악할 수 있었음.**

 - Pivot_Table
 - Heatmap에 사용하기 위해 필요한 데이터 가공단계 ( SQL과 같은 기능 )
     - ```groupby()```는 세로로 긴 형태의 결과물 / ```Pivot_Table```은 2차원 매트릭스 형태로 펼쳐줌
     - index = 행 / columns = 열 / values = 교차지점의 값 / aggfunc = 계산방식
     - aggfunc의 기본은 mean(평균) -> sum(합)으로 바꿔주어야 의도와 일치함

 - sns.그래프형태
 - 상세한 그래프는 matplotlib, 빠르고 예쁜 시각화는 seaborn으로 작성 (Matplotlib기반으로 만들어진 라이브러리)
 - 파라미터에서 hue를 통해 간단한 값 분리를 할 수 있었음
 - color가 아닌 palette 파라미터로 색 조정 가능.
 
 - plt.axvline() (axv : 수직선, axh : 수평선)
 - 학습 중 마주친 새로운 함수였고, 강조와 구분에 탁월하겠다 생각해 학습함.

 - 그래프 원(￦) 표시 -> 깨짐 현상 발생
     - 한글폰트 설치와 마이너스 부호 깨짐 방지 코드 적용
    **한글로 된 매핑자료를 만들고 **시각화**와 **전처리**에 용이해짐**

 - 결과 및 해석
     - ![AGE_TIME_Heatmap](../02_src/01_Data_study/AGE_TIME_HEATMAP.png)
     - 이천시에서 결제가 가장 활발한 연령층은 **40대와 50대**이며, 경제활동 인구인 20대부터 은퇴 연령층인 70대까지 모두 일정한 소비력을 갖는 **‘결제 연령층’**이다.
     - **09시-21시** 사이에 소비가 가장 많이 이루어지며, 특히 **점심(11-13시)**과 **저녁(17-19시)** 시간대가 두드러진다.
    
     - ![DAY_TIME_Heatmap](../02_src/01_Data_study/DAY_TIME_HEATMAP.png)    
     - **11-13시 / 17-19시** 구간에서 소비 성향이 가장 강하며, 그 사이 시간대는 상대적으로 감소한다.  
     - 특히 **목요일 저녁(17시)**에 소비량이 가장 크게 나타난다.  
     - 예상과 달리 주말보다 **화·수·목 요일의 매출 건수**가 더 높게 나타난다.

    → 이러한 패턴을 기반으로 **‘점심 특선’**, **‘주중 타임세일’** 등 시간대·요일 기반 마케팅 전략을 고려할 수 있다.

     - 가설
     - “목요일 회식 / 금요일은 개인 휴식” 같은 패턴이 존재할 것이다.
         - 근거
             - 목요일의 경우, 17시 이후에도 높은 건수가 유지된다.
        
         - 가설을 증명하기 위해서 **'음식'** 컬럼의 **요일별 매출금액·매출건수 비교 분석** 필요

     - 심화분석
         - 안정적 직장 또는 사회적 지위를 가진 연령층의 소비가 강하게 확인됨.
             -**4050 세대와 2030 세대가 각각 어떤 업종에 많이 소비하는가?**
             - 예측: 2030은 가성비, 데이트, 혹은 값비싼 음식에 ‘플렉스’하는 경향이 있을 수 있음 

         - **결제 주도권은 남성과 여성 중 어느 쪽이 더 강한가?**  
             - 이 부분은 후속 프로젝트로 진행 예정.

         - 주말보다 화·수·목에 매출 건수가 높은 이유를 파악하기 위해 **다른 월을 포함한 전체 일 별 매출금액과 건수확인**이 필요.
             - 원래 패턴이 화,수,목에 더 집중되는 것인지 파악
             - 7월이 이상데이터일 가능성 확인



### TIL (간단한 Keyword 정리)
 - Heatmap(data, cmap, annot, annot_kws, fmt, cbar, cbar_kws )
     - Heatmap을 사용하기 위해서는 Pivot_Table로 먼저 가공해야한다는 점.
     - '*_kws'를 통한 폰트 설정, label 설정

 - Pivot_Table(index, column, values, aggfunc)
 - .reset_index() / sns.그래프형태 ->(hue='원하는 구분', palette='')
 - plt.axvline(x, color, labels, linewidth, linestyle) 수직선.

 - 한글폰트 설치법(마이너스 부호 깨짐 방지)

## 트러블슈팅 (Troubleshooting)

### 1. 불편한 시각화
- **문제 :** Heatmap맵 데이터 구조 불일치 (Heatmap은 2차원 구조이기 때문)
- **방법 :** Pivot_Table 학습
- **결과 :** 연령대별 시간대 소비 집중 구간을 직관적으로 도출

### 2. 한글 폰트 깨짐  
- **문제 :** 시각화 과정에서 한글 및 기호가 깨지는 현상 발생  
- **원인 :** Matplotlib은 기본적으로 영문 폰트를 사용하며, 한글 폰트 경로를 캐싱하지 못해 깨짐 발생
- **방법 :** 폰트 매니저를 통해 경로를 직접 지정하거나 rcParams을 수정해야 함.
- **결과 :** 경로를 직접 지정하여 한글 폰트 설치
- **추가 기능** 한글로 된 매핑자료를 만들었고 '시각화'와 '전처리'에 용이해졌음

### 추가 공부
 - [x] .collections[0] *무슨 기능인가요 ?* -> 도형들의 리스트(집합) -> 깊이 있는 제어를 할 때 필요
 - [x] cbar = ax.collections[0].colorbar *왜 이렇게 사용하는건가요?* -> 객체지향적으로 세밀하게 다룰 수 있음
 - [ ] Github Markdown -> 학습 중

# 📅 개발 및 학습 일지 (Development Log)
## 08.Dec.2025 [DAY-1] (Colab 활동)
## ✅ 한 일
 - [x] 데이터 전처리 방법 숙지
 - [x] 함수와 파라미터 학습


### 상황
 - 당시 노트북 성능문제로 Colab에서 데이터 전처리 시작.

## 배운점(TIL)
 - 데이터 불러오기
 - '.csv'파일을 pd.read_excel로 불러오는 바람에 실패했음
     - '.csv'와 '.xlsx' 구분
     - 컴퓨터가 파일경로를 읽는 법 파악.
     - .copy()를 통한 데이터 복사
 
 - 컬럼 가공
     - 책에서 학습한 기능들을 직접 사용해보고자 함
     - df.drop() 사용할 때 axis(축)을 지정해줘야하며 즉시 적용은 inplace=T임. 
     - .map() 함수를 사용해 매핑

 - 메모리 사용량
 - 데이터의 양이 많아 메모리 사용량을 줄이고자 함.
     - .astype()을 통한 컬럼의 category 타입화 
     - 하지만 바뀌지 않았고 df.drop()안에 있는 inplace=T 파라미터를 사용해도 불가능했음
     - df['컬럼'] = df['컬럼'].astype('category')코드를 통해 적용 (49.1+ MB -> 16.9 MB 약 65% 절감)
 
 - Pieplot
 - Pieplot으로 시각화
     - 컬럼의 값들이 많아 비중이 적을 수록 글씨가 겹침.
     - 적은 비중의 값들은 기준값변수를 생성하고 'etc' 컬럼을 만들어 합침
     - 퍼센트 뿐 만 아니라 금액(KRW)을 추가하고 싶었음
         - plt.text를 통해 값이 담긴 리스트 생성 후 적용
         - autopct 값을 None으로 조정하고 리스트 생성에 {value;,} / {value:.1f} 등 표현방법 구현
         - 글씨 크기와 글씨 조정을 위해 labeldistance 파라미터, textprops로 조정
     - seaborn의 color_palette()를 통해 pieplot에 colors 파라미터 사용

 - Pieplot의 범례
     - etc 값들을 범례로 따로 표시하고 싶었음
         - 숙련도 이슈로 실패함
         - 대신 '텍스트 박스'라는 개념을 도입(bbox_to_anchor)
    **하지만**, 가독성의 문제로 많은 양의 데이터를 시각화하기에는 Pieplot보다는 'Horizontal Bar Chart'가 더 좋을 것같음.

## TIL(간단한 Keyword 정리)
 - plt.figure(figsize=(x,y))
 - plt.pie(x, labels, autopct, colors, explode, labeldistance, textprops)
 - df.groupby('')[''] -> ()묶은 그룹의 []원하는 컬럼
 - {value:.1f} or (value:,) 등 표현방법

### 추가 공부
 - [x] plt.legend(bbox_to_anchor) -> *bbox_to_anchor(bbox)* : 배경상자 속성으로, 네모난 경계 영역을 생성함

---
## 프로젝트 목표
1. Python 및 데이터 분석 전반에 익숙해지기  

   - (최종 목표: **실무 2~3년차 수준**을 향한 성장)

2. 데이터 기반 **인사이트 도출 및 패턴 발견**

3. 연령별 **타겟 마케팅 전략** 수립

4. **PPT 발표 수준의 분석 자료 제작**

## 평가기준
 - 동네를 잘 모르는 사람도 전략을 이해할 수 있어야 함.

 - 그래프가 이해하기 쉽고 타당하며 가독성, 심미성, 전문성을 챙겼는가?

 - 신뢰성이 있는 자료인가?

 - 코드의 비효율성이 있었는가 ? 

 - 인사이트를 도출하고 전략을 수립했는가 ? 

 - 사용자의 Python 및 데이터 분석 스킬이 늘었는가 ? 

## 분석 환경 및 도구 (Tech Stack)

- **Language:** Python 3.14  

- **Data Handling:** Pandas (데이터 전처리, 피벗테이블)  

- **Visualization:** Matplotlib, Seaborn (히트맵, 서브플롯)  

- **Environment:** VS Code, Git / GitHub  

- **Module:** `config.py` 기반 전역 설정(폰트, 매핑) 모듈화


